{
  "proxyPort": 8080,
  "managementPort": 8081,
  "ollamaEndpoint": "http://localhost:11434",
  "ollamaModel": "qwen2.5:3b",
  "useAIDetection": true,
  "aiConfidenceThreshold": 0.7,
  "ollamaMaxConcurrent": 1,
  "logLevel": "info",
  "caCertFile": "ca-cert.pem",
  "caKeyFile": "ca-key.pem",
  "bindAddress": "127.0.0.1",
  "managementToken": "",
  "upstreamProxy": "",
  "aiApiDomains": [
    "api.anthropic.com",
    "api.openai.com",
    "api.cohere.ai",
    "generativelanguage.googleapis.com",
    "api.mistral.ai",
    "api.together.xyz",
    "api.perplexity.ai",
    "api.replicate.com",
    "api.huggingface.co"
  ],
  "authDomains": [
    "accounts.google.com",
    "login.microsoftonline.com",
    "auth0.com",
    "okta.com"
  ],
  "authPaths": [
    "/auth", "/login", "/signin", "/signup", "/register",
    "/token", "/oauth", "/authenticate", "/session",
    "/v1/auth", "/api/auth", "/api/login", "/api/token"
  ],
  "piiInstructions": {
    "claude": "PRIVACY TOKENS: This request contains privacy-preserving placeholders matching the pattern [PII_XXXXXXXX] (8 hex characters). You MUST reproduce every such token EXACTLY as written in your response. Do NOT replace them with example values, email addresses, phone numbers, names, or any other substitutes. Treat [PII_*] tokens as opaque identifiers that must pass through unchanged.",
    "gpt": "PRIVACY TOKENS: This request contains privacy-preserving placeholders matching the pattern [PII_XXXXXXXX] (8 hex characters). Reproduce every such token verbatim in your response. Do not substitute them with example values.",
    "default": "PRIVACY TOKENS: This request contains privacy-preserving placeholders matching the pattern [PII_XXXXXXXX] (8 hex characters). Reproduce every such token verbatim in your response. Do not substitute them with example values."
  }
}
